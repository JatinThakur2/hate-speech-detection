
MODEL ARCHITECTURE SUMMARY
============================================================

1. IMAGE ENCODER (ResNet-50)
    - Input: RGB Images (224 × 224 × 3)
    - Pre-trained: ImageNet weights
    - Output: 512-dimensional feature vector
    - Parameters: **FINE-TUNED** (All layers trainable)

2. TEXT ENCODER (BERT-base-uncased)
    - Input: Tokenized text (max length: 128)
    - Pre-trained: BERT-base-uncased
    - Output: 512-dimensional feature vector
    - Parameters: FINE-TUNED

3. FUSION LAYER
    - Concatenation: Image (512) + Text (512) $\rightarrow$ 1024
    
4. CLASSIFIER
    - Layer 1: Linear(1024 $\rightarrow$ 256) + ReLU + **Dropout(0.5)**
    - Layer 2: Linear(256 $\rightarrow$ 2)
    - Output: Binary classification (Non-Hate/Hate)

TRAINING CONFIGURATION
============================================================
Optimizer: AdamW (lr=2e-05, **weight\_decay=1e-4**)
Scheduler: **CosineAnnealingLR**
Loss Function: Cross-Entropy Loss (with **Class Weights**)
Class Weights: Non-Hate=0.7754, Hate=1.4078
Batch Size: 16
Epochs: 3
Device: cuda

DATASET STATISTICS
============================================================
Training Samples: 8500
Validation Samples: 500
Non-Hate (Class 0): Train=5481, Val=253
Hate (Class 1): Train=3019, Val=247
